stages:
  - stage: lint
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: lint
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: 3.7
            displayName: 'Use Python 3.7'

          - script: |
              pip install isort[requirements]==5.4.2 flake8==3.8.3 black==20.8b1 pyupgrade==2.7.2
              EXIT_STATUS=0
              isort . --check-only --skip docs/ || EXIT_STATUS=$?
              black --check --exclude docs/ . || EXIT_STATUS=$?
              flake8 great_expectations/core || EXIT_STATUS=$?
              pyupgrade --py3-plus || EXIT_STATUS=$?
              exit $EXIT_STATUS

  - stage: cloud_db_integration_expectations_cfe
    pool:
      vmImage: 'ubuntu-latest'

    dependsOn: [lint]

    jobs:
      - job: bigquery_expectations_cfe
        timeoutInMinutes: 0 # Maximize the time that pipelines remain open (6 hours currently)

        variables:
          python.version: '3.8'

        steps:
          # delay the execution of the second stages so that we do not hit the rate limit for BigQuery
          # - bash: sleep 5m
          #  displayName: Delay for BigQuery rate limit

          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip==20.2.4
            displayName: 'Update pip'

          - script: |
              pip install -r requirements-dev.txt

            displayName: 'Install dependencies'

          - task: DownloadSecureFile@1
            name: gcp_authkey
            displayName: 'Download Google Service Account'
            inputs:
              secureFile: 'superconductive-service-acct.json'
              retryCount: '2'

          - script: |
              pip install pytest pytest-azurepipelines
              pytest -v --no-spark --no-postgresql --bigquery --napoleon-docstrings --junitxml=junit/test-results.xml --cov=. --cov-report=xml --cov-report=html --ignore=tests/cli --ignore=tests/integration/usage_statistics tests/test_definitions/test_expectations_cfe.py

            displayName: 'pytest'
            env:
              GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
              GCP_PROJECT: $(GCP_PROJECT)
              GCP_BIGQUERY_DATASET: $(GCP_BIGQUERY_DATASET)

#  - stage: cloud_db_integration_expectations
#    pool:
#      vmImage: 'ubuntu-latest'
#
#    dependsOn: [cloud_db_integration_expectations_cfe, lint]
#    jobs:
#      - job: bigquery_expectations
#        timeoutInMinutes: 0 # Maximize the time that pipelines remain open (6 hours currently)
#
#        variables:
#          python.version: '3.8'
#
#        steps:
#          - task: UsePythonVersion@0
#            inputs:
#              versionSpec: '$(python.version)'
#            displayName: 'Use Python $(python.version)'
#
#          - bash: python -m pip install --upgrade pip==20.2.4
#            displayName: 'Update pip'
#
#          - script: |
#              pip install -r requirements-dev.txt
#
#            displayName: 'Install dependencies'
#
#          - task: DownloadSecureFile@1
#            name: gcp_authkey
#            displayName: 'Download Google Service Account'
#            inputs:
#              secureFile: 'superconductive-service-acct.json'
#              retryCount: '2'
#
#          - script: |
#              pip install pytest pytest-azurepipelines
#              pytest -v --no-spark --no-postgresql --bigquery --napoleon-docstrings --junitxml=junit/test-results.xml --cov=. --cov-report=xml --cov-report=html --ignore=tests/cli --ignore=tests/integration/usage_statistics tests/test_definitions/test_expectations.py
#
#            displayName: 'pytest'
#            env:
#              GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
#              GCP_PROJECT: $(GCP_PROJECT)
#              GCP_BIGQUERY_DATASET: $(GCP_BIGQUERY_DATASET)
